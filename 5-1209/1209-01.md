# 决策树算法

## 1.原理

常用的决策树有ID3（分类），C4.5（分类），CART（分类或回归），GBDT（回归或分类）等。

ID3根据**信息增益**选择划分数据的特征。

C4.5根据**信息增益比**选择划分数据的特征。

CART根据**基尼系数**选择划分数据的特征。

GBDT通过**最小化平方误差**选择划分数据的特征。



决策树**分类**算法的原理：分类决策树模型是一种描述对实例进行分类的树形结构，决策树由结点和有向边组成，结点分为内部结点和叶结点两种类型，内部结点表示一个特征或属性，叶结点表示一个分类。

用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点，这时每个子结点对应着该特征的一个取值，如此递归地对实例进行测试并分配，直至达到叶结点，最后将实例分到叶结点的类中。

## 2.优缺点

#### 优点：

计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。

#### 缺点：

可能会产生过度匹配问题。

## 3.适用数据范围

数值型和标称型。